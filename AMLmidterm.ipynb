{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aQoMk--DCfN"
      },
      "source": [
        "This template notebook should serve as a guide for how to load and manipulate the dataset, and the different preprocessing methods you may choose to implement (you are welcome to try any others outside of what is provided here). This code should be treated as pseudo-code - and you may have to debug this code to get it working adequately.\n",
        "\n",
        "In this notebook, we only access the labeled portion of the training dataset, and directly run/train/fit supervised methods. e.g., Multinomial Naive Bayes and Linear SGD classifiers (linear SGD [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html] implements regularized linear models with stochastic gradient descent, e.g., by choosing loss=‘log_loss’, you obtain a logistic regression classifier), on only this labeled portion of the training dataset. The performance values you get from running this experiment will serve as your baseline.\n",
        "\n",
        "Once you have these baseline numbers for the configuration of preprocessing and supervised methods you choose (ideally at least 2 preprocessing methods and also at least 2 supervised methods), you can now begin working on Part 1: i.e. using unsupervised learning methods to automate adding labels to the unlabelled portion of the train dataset. The goal is to see if adding these newly labeled data examples to the train set will improve the baseline numbers you obtained (i.e. Part 2: running the supervised methods you chose for the baseline on the newly augmented dataset and reporting the performance on this augmented dataset).\n",
        "\n",
        "Lastly, please note that there is a class imbalance in the train, test, and val sets. You will have to incorporate an approach to deal with this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0DBGcZfs0FJ",
        "outputId": "d626fbee-7fda-45d0-ebd1-6ed986610bb2"
      },
      "outputs": [],
      "source": [
        "# e.g. if using google colab import drive, uncomment lines below\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LX0ia6JVtFjr"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression as sk_OLS\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD0dQabauB7z"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uRBDrBxYtBbk"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "val_data = pd.read_csv('val.csv')\n",
        "test_data = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COVSCAfadeb2",
        "outputId": "98ef4bf3-943e-461c-e13c-4f6fe1fad5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Shape: (59706,)\n",
            "Cleaned Train Data Shape: (24758,)\n",
            "Validation Data Shape: (23256,)\n",
            "Test Data Shape: (23257,)\n",
            " \n",
            "Number of labels = 0 in train dataset as percentage: 8.33%\n",
            "Number of labels = 1 in train dataset as percentage: 8.95%\n",
            "Number of labels = 2 in train dataset as percentage: 5.33%\n",
            "Number of labels = 3 in train dataset as percentage: 9.60%\n",
            "Number of labels = 4 in train dataset as percentage: 9.26%\n",
            "Number of labels = -100 in train dataset as percentage: 58.53%\n",
            " \n",
            "Number of labels = 0 in val dataset as percentage: 19.63%\n",
            "Number of labels = 1 in val dataset as percentage: 20.27%\n",
            "Number of labels = 2 in val dataset as percentage: 20.42%\n",
            "Number of labels = 3 in val dataset as percentage: 19.81%\n",
            "Number of labels = 4 in val dataset as percentage: 19.88%\n",
            "Number of labels = -100 in val dataset as percentage: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# get all train data (labelled and unlabelled)\n",
        "X_train    = train_data['Phrase']\n",
        "y_train    = train_data['Sentiment']\n",
        "\n",
        "# get only labelled train data\n",
        "mask = (y_train != -100)\n",
        "train_data_clean    = train_data[mask]\n",
        "X_train_clean    = X_train[mask]\n",
        "y_train_clean    = y_train[mask]\n",
        "\n",
        "# get val data\n",
        "X_val    = val_data['Phrase']\n",
        "y_val    = val_data['Sentiment']\n",
        "\n",
        "# get test data\n",
        "X_test     = test_data['Phrase']\n",
        "\n",
        "print(f\"Train Data Shape: {X_train.shape}\")\n",
        "print(f\"Cleaned Train Data Shape: {train_data_clean['Phrase'].shape}\")\n",
        "print(f\"Validation Data Shape: {X_val.shape}\")\n",
        "print(f\"Test Data Shape: {X_test.shape}\")\n",
        "\n",
        "print(\" \")\n",
        "print(f\"Number of labels = 0 in train dataset as percentage: {((y_train == 0).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in train dataset as percentage: {((y_train == 1).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in train dataset as percentage: {((y_train == 2).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in train dataset as percentage: {((y_train == 3).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in train dataset as percentage: {((y_train == 4).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = -100 in train dataset as percentage: {((y_train == -100).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "\n",
        "print(\" \")\n",
        "print(f\"Number of labels = 0 in val dataset as percentage: {((y_val == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((y_val == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((y_val == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((y_val == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((y_val == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = -100 in val dataset as percentage: {((y_val == -100).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xlccu-qCz18"
      },
      "source": [
        "# Define Preprocessing Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5v2_Ro6ca5I",
        "outputId": "efd0ad1b-a203-4b8a-a8a0-36946906f7b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def clean(text):\n",
        "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', str(text), flags=re.MULTILINE)\n",
        "    texter = re.sub(r\"<br />\", \" \", text)\n",
        "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
        "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
        "    texter = re.sub('\\n', \" \", texter)\n",
        "    texter = re.sub(' u ',\" you \", texter)\n",
        "    texter = re.sub('`',\"\", texter)\n",
        "    texter = re.sub(' +', ' ', texter)\n",
        "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
        "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
        "    texter = re.sub('&amp;', 'and', texter)\n",
        "    texter = re.sub('\\r', ' ',texter)\n",
        "    #added substitutions\n",
        "\n",
        "    #***********added substitutions***********\n",
        "    # remove all the special characters\n",
        "    texter = re.sub(r'\\W', ' ', texter)\n",
        "    # remove all single characters\n",
        "    texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
        "    # Remove single characters from the start\n",
        "    texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
        "    # Remove numbers\n",
        "    texter = re.sub(r'\\d+', ' ', texter)\n",
        "    # Converting to Lowercase\n",
        "    texter = texter.lower()\n",
        "    # Remove punctuation\n",
        "    texter = re.sub(r'[^\\w\\s]', ' ', texter)\n",
        "    # Remove parentheses\n",
        "    texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
        "    # Remove single quotes\n",
        "    texter = re.sub(r'\\'', ' ', texter)\n",
        "    # Substituting multiple spaces with single space\n",
        "    texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
        "\n",
        "    clean = re.compile('<.*?>')\n",
        "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
        "    texter = re.sub(clean, '', texter)\n",
        "    if texter == \"\":\n",
        "        texter = \"\"\n",
        "    return texter\n",
        "\n",
        "def clean_dataset(dataset):\n",
        "    for row in range(dataset.shape[0]):\n",
        "        dataset[row,0] = clean(dataset[row,0])\n",
        "    return dataset\n",
        "\n",
        "def tokenize_lexicon(texts):\n",
        "    return_texts = []\n",
        "    for i in range(len(texts)):\n",
        "        return_texts.append(nltk.word_tokenize(texts[i]))\n",
        "        return_texts[i] = nltk.pos_tag(return_texts[i])\n",
        "    return return_texts\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    else:\n",
        "        return wn.NOUN\n",
        "\n",
        "def lemmatize_texts(texts):\n",
        "    return_texts = []\n",
        "    lemmer = nltk.stem.WordNetLemmatizer()\n",
        "    for i in range(len(texts)):\n",
        "        return_texts.append([])\n",
        "        for j in range(len(texts[i])):\n",
        "                return_texts[i].append(lemmer.lemmatize(texts[i][j][0], pos=get_wordnet_pos(texts[i][j][1])))\n",
        "    return return_texts\n",
        "\n",
        "def stem_texts(texts):\n",
        "    return_texts = []\n",
        "    ps = PorterStemmer()\n",
        "    for i in range(len(texts)):\n",
        "        return_texts.append([])\n",
        "        for j in range(len(texts[i])):\n",
        "                return_texts[i].append(ps.stem(texts[i][j][0]))\n",
        "    return return_texts\n",
        "\n",
        "\n",
        "def backtostring(texts):\n",
        "    return_texts = []\n",
        "    for i in range(len(texts)):\n",
        "        return_texts.append(\" \".join(texts[i]))\n",
        "    return return_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_XKPAT4grMt"
      },
      "source": [
        "# Preprocess using Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWpMOdJ2uipq",
        "outputId": "426663c2-bce6-484a-9129-a6361491ca21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "def pre_process(data):\n",
        "    preproc_data = data.copy()\n",
        "    preproc_data = preproc_data.str.lower()\n",
        "    punctuation = string.punctuation\n",
        "    mapping = str.maketrans(\"\", \"\", punctuation)\n",
        "    preproc_data = preproc_data.str.translate(mapping)\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    preproc_data = preproc_data.apply(lambda text: ' '.join([word for word in str(text).split() if word.lower() not in stop_words]))\n",
        "    nltk.download('wordnet')\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    preproc_data = preproc_data.apply(lambda text: ' '.join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
        "    preproc_data = preproc_data.apply(lambda text: re.sub(r'@\\w+', '', re.sub(r'http\\S+|www\\S+', '', text)))\n",
        "    return preproc_data\n",
        "\n",
        "# get the preprocessed data\n",
        "X_train_preproc   = pre_process(X_train)\n",
        "X_train_clean_preproc   = pre_process(X_train_clean)\n",
        "X_val_preproc = pre_process(X_val)\n",
        "X_test_preproc = pre_process(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GhiuEjdumEO"
      },
      "source": [
        "Bag of words model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-ES4zksi-z2J"
      },
      "outputs": [],
      "source": [
        "combined_data = pd.concat([X_train_preproc, X_val_preproc, X_test_preproc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "sdBuYWZ1-knR",
        "outputId": "a65f7aa1-beda-4c87-c742-d8dec0d832b8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text_data = combined_data\n",
        "words = ' '.join(text_data).split()\n",
        "word_freq_dict = Counter(words)\n",
        "\n",
        "word_frequencies = list(word_freq_dict.values())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(word_frequencies, bins=55, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Word Frequency')\n",
        "plt.ylabel('Number of Words that show up X times')\n",
        "plt.title('Distribution of Word Frequencies')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fD4ZzrPQuo7B"
      },
      "outputs": [],
      "source": [
        "def bag_of_word(data,  threshold_M):\n",
        "    vectorizer = CountVectorizer(binary=True, max_features= threshold_M)\n",
        "    vectorizer.fit(combined_data)\n",
        "    X = vectorizer.transform(data)\n",
        "    featurized_data = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
        "    return featurized_data\n",
        "\n",
        "# get the featurized data\n",
        "X_train   = bag_of_word(X_train_preproc, 8)\n",
        "X_train_clean = bag_of_word(X_train_clean_preproc, 8)\n",
        "X_val = bag_of_word(X_val_preproc, 8)\n",
        "X_test = bag_of_word(X_test_preproc, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6o6quWYA4dm"
      },
      "source": [
        "Sklearn Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VSmj-gV0ES9I"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = MultinomialNB(alpha=1e-3)\n",
        "clf.fit(X_train_clean, y_train_clean)\n",
        "sk_y = clf.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwgerXc2HPeP",
        "outputId": "e6051efa-4911-4ef5-ba63-fcd68096a715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels = 0 in val dataset as percentage: 4.11%\n",
            "Number of labels = 1 in val dataset as percentage: 11.18%\n",
            "Number of labels = 2 in val dataset as percentage: 7.80%\n",
            "Number of labels = 3 in val dataset as percentage: 71.02%\n",
            "Number of labels = 4 in val dataset as percentage: 5.89%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X71WprhUHBe_"
      },
      "source": [
        "Sklearn Linear SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Zpe4FRF32u",
        "outputId": "b0c5d73c-58d3-4980-ffb8-cae3fa1bd835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.2819487444100447\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
        "clf_sgd.fit(X_train_clean, y_train_clean)\n",
        "y_pred = clf_sgd.predict(X_val)\n",
        "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
        "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
        "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
        "# print(clf_sgd.predict_proba(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wDYD96AGxom",
        "outputId": "3e8898ff-9863-448a-8339-2bed7ed40213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels = 0 in val dataset as percentage: 0.01%\n",
            "Number of labels = 1 in val dataset as percentage: 0.16%\n",
            "Number of labels = 2 in val dataset as percentage: 7.90%\n",
            "Number of labels = 3 in val dataset as percentage: 83.31%\n",
            "Number of labels = 4 in val dataset as percentage: 8.62%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSQOZqupuKGO"
      },
      "source": [
        "# Preprocess the data using CountVectorizer, nltk stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4LDKgHgiMpa",
        "outputId": "504677a3-1002-4e74-ea37-394029211845"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt_tab to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to\n",
            "[nltk_data]    |     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emilygelchie/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24758,)\n",
            "(23256,)\n",
            "(23257,)\n",
            "(71271,)\n",
            "(71271, 100)\n",
            "X_data.shape:  (71271, 100)\n",
            "X_train.shape:  (24758, 100)\n",
            "X_val.shape:  (23256, 100)\n",
            "X_test.shape:  (23257, 100)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"all\")\n",
        "# Add these downloads before the preprocessing code\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "lemma = True\n",
        "\n",
        "# Rest of your code remains the same\n",
        "train = clean_dataset(np.array(train_data_clean))\n",
        "val = clean_dataset(np.array(val_data))\n",
        "test = clean_dataset(np.expand_dims(np.array(test_data[\"Phrase\"]), axis=1))\n",
        "print(train[:,0].shape)\n",
        "print(val[:,0].shape)\n",
        "print(test[:,0].shape)\n",
        "print(np.concatenate((train[:,0], test[:,0], val[:,0])).shape)\n",
        "\n",
        "token_texts = tokenize_lexicon(np.concatenate((train[:,0], val[:,0], test[:,0])))\n",
        "\n",
        "del train\n",
        "del val\n",
        "del test\n",
        "\n",
        "if(lemma):\n",
        "    lemm_texts = lemmatize_texts(token_texts)\n",
        "else:\n",
        "    lemm_texts = stem_texts(token_texts)\n",
        "del token_texts\n",
        "processed_texts = backtostring(lemm_texts)\n",
        "del lemm_texts\n",
        "# matrix counts\n",
        "vectorizer = CountVectorizer(input='content', stop_words='english', min_df=3, max_features = 100)\n",
        "X = vectorizer.fit_transform(processed_texts)\n",
        "del processed_texts\n",
        "del vectorizer\n",
        "X_dense = X.todense()\n",
        "print(X_dense.shape)\n",
        "del X\n",
        "\n",
        "# tfidf\n",
        "tfidf_vectorizer = TfidfTransformer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(np.array(X_dense))\n",
        "del X_dense\n",
        "X_data = (np.array(X_tfidf.todense()))\n",
        "print(\"X_data.shape: \", X_data.shape)\n",
        "\n",
        "X_train = X_data[:train_data_clean['Phrase'].shape[0]]\n",
        "X_val = X_data[train_data_clean['Phrase'].shape[0]:train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]]\n",
        "X_test = X_data[train_data_clean['Phrase'].shape[0]+val_data['Phrase'].shape[0]:]\n",
        "del X_data\n",
        "print(\"X_train.shape: \", X_train.shape)\n",
        "print(\"X_val.shape: \", X_val.shape)\n",
        "print(\"X_test.shape: \", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZyTz60oE2Ml"
      },
      "source": [
        "Sklearn Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuPqD9lShdPQ",
        "outputId": "d9ee8f99-4ae7-4d05-f88b-95b4378fa3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5913312693498453\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = MultinomialNB(alpha=1e-3) # tried 1,10,100,1e-3\n",
        "clf.fit(X_train, y_train_clean)\n",
        "sk_y = clf.predict(X_val)\n",
        "y_test_pred = clf.predict(X_test)\n",
        "# print(\"Feature Count \\n\",clf.feature_count_)\n",
        "# print(\"Class Log Prior \",clf.class_log_prior_)\n",
        "print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
        "# print(clf.predict_proba(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5cV_v97hdPU",
        "outputId": "9e168082-fc6b-4f96-a7c8-ad6091ce23e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels = 0 in val dataset as percentage: 13.95%\n",
            "Number of labels = 1 in val dataset as percentage: 13.80%\n",
            "Number of labels = 2 in val dataset as percentage: 16.09%\n",
            "Number of labels = 3 in val dataset as percentage: 35.32%\n",
            "Number of labels = 4 in val dataset as percentage: 20.83%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yko5XY2ME3E2"
      },
      "source": [
        "Sklearn SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY8LDnqghdPV",
        "outputId": "2f5349e0-ac0e-41ea-93ee-7234802d0516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5706914344685242\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
        "clf_sgd.fit(X_train, y_train_clean)\n",
        "y_val_pred = clf_sgd.predict(X_val)\n",
        "y_test_pred = clf.predict(X_test)\n",
        "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
        "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
        "print('Accuracy: ', accuracy_score(y_val, y_val_pred))\n",
        "# print(clf_sgd.predict_proba(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfoPr89LhdPV",
        "outputId": "9a375056-81b9-4a33-cc0f-a10bc3f8d0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels = 0 in val dataset as percentage: 0.01%\n",
            "Number of labels = 1 in val dataset as percentage: 0.16%\n",
            "Number of labels = 2 in val dataset as percentage: 7.90%\n",
            "Number of labels = 3 in val dataset as percentage: 83.31%\n",
            "Number of labels = 4 in val dataset as percentage: 8.62%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWn4WbbPdKMY"
      },
      "source": [
        "# Preprocess using Glove\n",
        "\n",
        "Download the \"glove.6B.300d.txt\" embedding file from [this link](http://nlp.uoregon.edu/download/embeddings/). WARNING: THIS IS A 1GB DOWNLOAD.\n",
        "\n",
        "The following pseudo-code is erroneous/buggy -> you will have to debug this code to generate your feature vectors based on the GLoVe embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BuN9Qd4IcR5n"
      },
      "outputs": [],
      "source": [
        "glove = {}\n",
        "dimension_of_glove = 300\n",
        "with open(\"/Users/emilygelchie/Downloads/glove.6B.300d.txt\", \"r\") as f: # if 'r' fails with unicode error, please use 'rb'\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        glove[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pzoXVJSxcR5n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400000\n"
          ]
        }
      ],
      "source": [
        "# Number of words\n",
        "print(len(glove.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NXz2xVVAcR5n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "# Embedding length\n",
        "for i in glove.values():\n",
        "    print(len(i))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xe_wD39JcR5o"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def get_keywords_as_list(df):\n",
        "    # Preprocess and get the keywords as a list of lists\n",
        "    raw_list_keywords = []\n",
        "    phrases = list(df[\"Phrase\"])\n",
        "    # print(phrases)\n",
        "    # print(type(phrases))\n",
        "    for idx, text in enumerate(phrases):\n",
        "        if idx == 0:\n",
        "            print(text)\n",
        "        # Each entry in \"keywords\" is a list of keywords. But they are stored as strings and not as a list.\n",
        "        # We need to convert this string to a list.\n",
        "        texter = text.lower()\n",
        "        # Remove single quotes\n",
        "        texter = re.sub(r'\\'', '', texter)\n",
        "        # Remove the [] at the start and end. Split entries by \", \"\n",
        "        text_as_list = texter.strip('[]').split(\", \")\n",
        "        raw_list_keywords.append(text_as_list)\n",
        "        if idx == 0:\n",
        "            print(raw_list_keywords)\n",
        "    return raw_list_keywords\n",
        "\n",
        "def clean_list_keywords(raw_lkeys):\n",
        "    cleaned_list_keywords = []\n",
        "    for lkeys in raw_lkeys:\n",
        "        cleaned_list_keywords.append([key for key in lkeys if key in glove.keys()])\n",
        "    return cleaned_list_keywords\n",
        "\n",
        "def normalize_vector(vec):\n",
        "    return vec / np.linalg.norm(vec,ord=2)\n",
        "\n",
        "def get_feature_list(cleaned_lkeys, glove_model):\n",
        "    feat_list = []\n",
        "    for lkeys in cleaned_lkeys:\n",
        "        # Zero initial value since we will average them glove_model values for all the keywords\n",
        "        # We use 'the' as an example key to get the number of dims.\n",
        "        # 'the' is a very common word and would be there in any training corpus.\n",
        "        rep_glove_vec = np.zeros(len(glove_model['the']))\n",
        "        for key in lkeys:\n",
        "            rep_glove_vec += glove_model[key]\n",
        "        rep_glove_vec /= len(lkeys)\n",
        "\n",
        "        # feat_list.append(normalize_vector(rep_glove_vec))\n",
        "        feat_list.append(rep_glove_vec)\n",
        "    return np.array(feat_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nfNuBc4icR5o"
      },
      "outputs": [],
      "source": [
        "def get_keywords_as_list(df):\n",
        "    raw_list_keywords = []\n",
        "    phrases = list(df[\"Phrase\"])\n",
        "\n",
        "    for idx, text in enumerate(phrases):\n",
        "        # Handle NaN or float values\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            text = str(text)  # Convert to string\n",
        "\n",
        "        # Convert to lowercase\n",
        "        texter = text.lower()\n",
        "\n",
        "        # Remove single quotes\n",
        "        texter = re.sub(r\"\\'\", \"\", texter)\n",
        "\n",
        "        # Split into words\n",
        "        text_as_list = texter.strip(\"[]\").split()  # Changed split(\", \") to split()\n",
        "\n",
        "        raw_list_keywords.append(text_as_list)\n",
        "\n",
        "        if idx == 0:  # Debug print for first item\n",
        "            print(f\"Original text: {text}\")\n",
        "            print(f\"Processed list: {text_as_list}\")\n",
        "\n",
        "    return raw_list_keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PTXvUmZScR5o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (24758, 300)\n",
            "X_val shape: (23256, 300)\n",
            "X_test shape: (23257, 300)\n"
          ]
        }
      ],
      "source": [
        "# 1. First define the helper functions\n",
        "def get_keywords_as_list(df):\n",
        "    raw_list_keywords = []\n",
        "    phrases = list(df[\"Phrase\"])\n",
        "\n",
        "    for idx, text in enumerate(phrases):\n",
        "        # Handle NaN or float values\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            text = str(text)\n",
        "\n",
        "        # Convert to lowercase\n",
        "        texter = text.lower()\n",
        "\n",
        "        # Remove single quotes\n",
        "        texter = re.sub(r\"\\'\", \"\", texter)\n",
        "\n",
        "        # Split into words\n",
        "        text_as_list = texter.strip(\"[]\").split()\n",
        "\n",
        "        raw_list_keywords.append(text_as_list)\n",
        "    return raw_list_keywords\n",
        "\n",
        "\n",
        "def clean_list_keywords(raw_lkeys):\n",
        "    cleaned_list_keywords = []\n",
        "    for lkeys in raw_lkeys:\n",
        "        cleaned_list_keywords.append([key for key in lkeys if key in glove.keys()])\n",
        "    return cleaned_list_keywords\n",
        "\n",
        "\n",
        "def get_feature_list(cleaned_lkeys, glove_model):\n",
        "    feat_list = []\n",
        "    for lkeys in cleaned_lkeys:\n",
        "        # Handle empty lists\n",
        "        if not lkeys:\n",
        "            rep_glove_vec = np.zeros(dimension_of_glove)\n",
        "        else:\n",
        "            rep_glove_vec = np.zeros(dimension_of_glove)\n",
        "            for key in lkeys:\n",
        "                rep_glove_vec += glove_model[key]\n",
        "            rep_glove_vec /= len(lkeys)\n",
        "        feat_list.append(rep_glove_vec)\n",
        "    return np.array(feat_list)\n",
        "\n",
        "\n",
        "# 2. Generate the keyword lists\n",
        "train_kws = clean_list_keywords(get_keywords_as_list(train_data_clean))\n",
        "val_kws = clean_list_keywords(get_keywords_as_list(val_data))\n",
        "test_kws = clean_list_keywords(get_keywords_as_list(test_data))\n",
        "\n",
        "# 3. Generate the feature vectors\n",
        "X_train = get_feature_list(train_kws, glove)\n",
        "X_val = get_feature_list(val_kws, glove)\n",
        "X_test = get_feature_list(test_kws, glove)\n",
        "\n",
        "# 4. Print shapes to verify\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FGyNJnnecbGh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24758, 300)\n",
            "(23256, 300)\n",
            "(23257, 300)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj_7lOBXE7nG"
      },
      "source": [
        "Sklearn Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JXgbOEmmcbI0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.37237702098383213\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Option 2: Scale features to be non-negative\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Then use MultinomialNB\n",
        "clf = MultinomialNB(alpha=1e-3)\n",
        "clf.fit(X_train_scaled, y_train_clean)\n",
        "sk_y = clf.predict(X_val_scaled)\n",
        "print(\"Accuracy: \", accuracy_score(y_val, sk_y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "BB1j_5SNcbK9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels = 0 in val dataset as percentage: 2.53%\n",
            "Number of labels = 1 in val dataset as percentage: 4.71%\n",
            "Number of labels = 2 in val dataset as percentage: 0.18%\n",
            "Number of labels = 3 in val dataset as percentage: 58.05%\n",
            "Number of labels = 4 in val dataset as percentage: 34.52%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr6P_V4EE7nH"
      },
      "source": [
        "Sklearn SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NcqDR65WcbNS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8028895768833849\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
        "clf_sgd.fit(X_train, y_train_clean)\n",
        "y_pred = clf_sgd.predict(X_val)\n",
        "# print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
        "# print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
        "print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
        "# print(clf_sgd.predict_proba(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "4aZdRV6pzd2s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "Number of labels = 0 in val dataset as percentage: 18.88%\n",
            "Number of labels = 1 in val dataset as percentage: 16.13%\n",
            "Number of labels = 2 in val dataset as percentage: 21.35%\n",
            "Number of labels = 3 in val dataset as percentage: 21.95%\n",
            "Number of labels = 4 in val dataset as percentage: 21.69%\n"
          ]
        }
      ],
      "source": [
        "print((y_pred == 2).all())\n",
        "\n",
        "print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZRRGm7AFXTY"
      },
      "source": [
        "# Part 1: Now that you have your baseline numbers, run your (at least 2) unsupervised algorithms on the unlabelled portion of your train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhiW-YaRFfaA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnvyM4VvFj-A"
      },
      "source": [
        "# Part 2: With your newly augmented dataset, re-run your supervised algorithms. How do the performance values change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6QLp6NJFu-s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
